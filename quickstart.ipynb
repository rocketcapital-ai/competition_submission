{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/gist/lubin-rci/7599bfff56aa9d0d0d230e7923421540/quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Welcome to the Yiedl Competition Quickstart Guide!\n",
    "\n",
    "This notebook will walk you through the required steps to take part in Yiedl's Updown and Neutral competitions.\n",
    "\n",
    "If you wish to run this without setting up a local Python and Jupyter environment, consider running this in Google Colab by clicking on the \"Open in Colab\" badge above.\n",
    "\n",
    "Let's begin!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "X0CqykZFY9J-"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install the `yiedl` package\n",
    "\n",
    "Requires Python >= 3.11"
   ],
   "metadata": {
    "id": "UFPg1S2Lr6NJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install yiedl-ai"
   ],
   "metadata": {
    "id": "urWimZP4ZT2b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import yiedl\n",
    "\n",
    "# configure logging to ensure output is shown in Jupyter/Colab\n",
    "import logging, sys\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout, force=True)"
   ],
   "metadata": {
    "id": "jXYXNn-Gax58"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set Demo Parameters\n",
    "\n",
    "⚠ **Make sure to set `demo_mode` correctly before running the other cells below.**\n",
    "\n",
    "- Demo mode: Set `demo_mode` to `True`.\n",
    "- Production mode: Set `demo_mode` to `False` or skip this section **after restarting the kernel**. The `yiedl` package is set to production mode settings by default.\n",
    "\n",
    "\n",
    "*Each challenge of the competition is only open on Mondays from around 0600 UTC.*\n",
    "\n",
    "*Demo competitions are available for development purposes any time of the week.*\n",
    "\n",
    "*Demo competitions run on the Polygon mainnet and use demo tokens.*\n",
    "\n"
   ],
   "metadata": {
    "id": "98gUh5PisHfW"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "QW_uiEIUY9KA"
   },
   "outputs": [],
   "source": [
    "demo_mode = True\n",
    "\n",
    "if not demo_mode:\n",
    "  yiedl.tools.UPDOWN_COMP.address = yiedl.settings.UPDOWN_ADDRESS\n",
    "  yiedl.tools.NEUTRAL_COMP.address = yiedl.settings.NEUTRAL_ADDRESS\n",
    "  yiedl.settings.TOKEN = yiedl.settings.TOKEN\n",
    "\n",
    "else:\n",
    "  demo_token_address = \"0xEF9B76BB9D37db69540766e264C6A950D7583dc1\"\n",
    "  demo_neutral = \"0x3d441c73859325e767088Bd295B024eaf655d5c8\"\n",
    "  demo_updown = \"0xbAa3d046F8970674474EfDc0A503C3E624E916c8\"\n",
    "  yiedl.tools.UPDOWN_COMP.address = demo_updown\n",
    "  yiedl.tools.NEUTRAL_COMP.address = demo_neutral\n",
    "  yiedl.settings.TOKEN = demo_token_address"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## User Account Keys"
   ],
   "metadata": {
    "id": "lgZ4CWfZya0p"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pinata JWT Token (for storing/pinning files on IPFS)\n",
    "\n",
    "`jwt`: This is a JSON Web Token (JWT) string that you can generate for free by creating a Pinata account. This will allow you to upload and pin files to IPFS, which is required for keeping submissions decentralized.\n",
    "\n",
    "[View this guide](https://docs.yiedl.ai/rci-competition/data-scientists/getting-started-via-automated-submissions/create-and-import-free-pinata-account) for a more visual set of instructions. Otherwise, follow the steps below:\n",
    "\n",
    "   1. Head over to [https://pinata.cloud](https://pinata.cloud) and sign up for a free account.\n",
    "   2. Log in to your [account's API key page](https://app.pinata.cloud/developers/api-keys).\n",
    "   3. Click on `+ New Key` on the top right.\n",
    "   4. Under `Key Name`, give the API Key a name, such as \"yiedl-submissions\".\n",
    "   5. Under \"Customize Permissions\" > \"Legacy Endpoints\" > \"Pinning\", check the box for `pinFileToIPFS`.\n",
    "   6. Leave all other fields as default.\n",
    "   7. **Copy the entire string in the `JWT` field and store it somewhere safe.** (The string should look something like \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.ey.......\")\n",
    "   8. Load this string into the `jwt` variable in the below cell."
   ],
   "metadata": {
    "id": "JmRXjpag0QBs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "jwt: str = ''\n",
    "\n",
    "# # example: loading from Google Colab Secrets (left panel)\n",
    "# from google.colab import userdata\n",
    "# jwt = userdata.get('jwt')"
   ],
   "metadata": {
    "id": "43YMhCfN0vTv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wallet Account Keys\n",
    "\n",
    "`address`: This is your wallet address. It should be a hex string beginning with \"0x\" followed by 40 characters.\n",
    "\n",
    "`pk`: This is the private key to your wallet address.\n",
    "\n",
    "*The private key can generally be found via the following steps. Some details may differ depending on the wallet version.*\n",
    "\n",
    "[View this guide](https://docs.yiedl.ai/rci-competition/data-scientists/getting-started-via-automated-submissions/create-and-import-polygon-account) for a more visual set of instructions for creating and importing the address and private key.\n",
    "\n",
    "Otherwise, follow the steps below. These assume that you already have a wallet set up with [Phantom](https://phantom.com/download) or [Metamask](https://metamask.io/).\n",
    "\n",
    "  - \"Phantom Wallet\": You can find the private key from the following steps:\n",
    "    1. Click on Phantom Wallet extension.\n",
    "    2. Click on top left account icon in the wallet window;\n",
    "    3. Click on settings icon at the bottom of the bar that appears;\n",
    "    4. Click on \"Manage accounts:;\n",
    "    5. Select the desired account;\n",
    "    6. Click on \"Show Private Key\";\n",
    "    7. Enter your password;\n",
    "    8. Click on \"Polygon\";\n",
    "    9. Click on disclaimer checkboxes and \"Continue\";\n",
    "    10. Copy password and store it somewhere safe.\n",
    "    11. Load this into the `pk` variable.\n",
    "\n",
    "  - \"Metamask\": You can find the private key from the following steps:\n",
    "    1. Click on Metamask Wallet extension;\n",
    "    2. Click on the account name on the top left;\n",
    "    3. Click on the 3-dot menu next to your desired account;\n",
    "    4. Click on \"Account Details\";\n",
    "    5. Click on \"Private Keys\";\n",
    "    6. Enter your passwoard;\n",
    "    7. Copy your private key for \"Polygon\" and store it somewhere safe.\n",
    "    8. Load this into the `pk` variable."
   ],
   "metadata": {
    "id": "jCb23vxW1OEe"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "⚠ **! Please keep your Private Key safe !**\n",
    "\n",
    "Stolen private keys lead to loss of funds from your blockchain wallet.\n",
    "\n",
    "Please take necessary steps to make sure your private key string is never exposed.\n",
    "\n",
    "This can include storing the key as a password-protected local environment variable, as well as keeping your computer safe from prying eyes or malware.\n",
    "\n",
    "If you are following this guide in a public area, please consider creating a separate account in a more private setting for use in your production code."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "5cONVE2xY9KC"
   },
   "outputs": [],
   "source": [
    "address = \"\"\n",
    "\n",
    "pk = \"\"\n",
    "\n",
    "\n",
    "# # example: loading from Google Colab Secrets (left panel)\n",
    "# from google.colab import userdata\n",
    "# pk = userdata.get('private_key')\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Check that the provided address belongs to the private key\n",
    "derived_address = yiedl.tools.get_account_address(pk)\n",
    "assert derived_address.lower() == address.lower(), \"The provided address does not match the private key.\""
   ],
   "metadata": {
    "id": "iqlbZeB788ec"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialise submitters\n",
    "The same wallet is used to initialise both submitters but we initialise 2 submitter instances: one for each competition."
   ],
   "metadata": {
    "id": "BSDGhP8R9O52"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "updown_submitter = yiedl.Submitter(jwt, address, yiedl.tools.CompetitionIds.UPDOWN, pk)\n",
    "neutral_submitter = yiedl.Submitter(jwt, address, yiedl.tools.CompetitionIds.NEUTRAL, pk)"
   ],
   "metadata": {
    "id": "FOgTyyC18pNZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download Weekly Dataset\n",
    "\n",
    "The weekly dataset is the same for both competitions, so we can use either submitter instance to perform the download.\n",
    "\n",
    "By default, the datasets are downloaded and unzipped to the \"datasets/weekly_dataset\" folder."
   ],
   "metadata": {
    "id": "DZrj0bSH9695"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "El30aoEqY9KD"
   },
   "outputs": [],
   "source": [
    "dataset_dir = updown_submitter.download_and_unzip_weekly_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download Daily Dataset (optional)\n",
    "\n",
    "A daily dataset is also available.\n",
    "The daily dataset is the same for both competitions, so we can use either submitter instance to perform the download.\n",
    "By default, the datasets are downloaded and unzipped to the \"datasets/daily_dataset\" folder.\n",
    "\n",
    "The daily dataset is much larger than the weekly one - for the purposes of this quickstart guide, we will stick to the weekly dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# daily_dataset_dir = updown_submitter.download_and_unzip_daily_dataset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "NNKYI1u7Y9KE"
   },
   "source": [
    "# Generate predictions from dataset\n",
    "\n",
    "The following is an example to demonstrate what needs to go into the csv file used for submission to both the *Neutral* and *Updown* competitions."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Setup"
   ],
   "metadata": {
    "id": "8lyD6rb1-r6f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "66F6NRQjY9KE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "kb-Nja4JY9KE"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataset_path = os.path.join(dataset_dir, yiedl.settings.YIEDL_TRAIN_FILE_PATH)\n",
    "validation_dataset_path = os.path.join(dataset_dir, yiedl.settings.YIEDL_VALIDATION_FILE_PATH)\n",
    "\n",
    "train_dataset  = pd.read_csv(train_dataset_path, index_col = 'date')\n",
    "validation_dataset  = pd.read_csv(validation_dataset_path, index_col = 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "95dxRS8DY9KF"
   },
   "outputs": [],
   "source": [
    "# first column (symbol) is the ticker\n",
    "# 'target_updown' is the return of a given crypto, such that final_price / initial_price - 1\n",
    "# 'target_neutral' is the rank by Era using 'target_updown'\n",
    "# the rest of the columns are features to be used for ML\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "JBI9_cbwY9KF"
   },
   "outputs": [],
   "source": [
    "# validation_dataset is the latest data from most recent Era\n",
    "# it has the same structure as the dataset, however 'target_updown' and 'target_neutral' are NaN\n",
    "validation_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "S2k_4lzOY9KF"
   },
   "source": [
    "### Create X and y from dataset\n",
    "- Currently there are 2 competitions user could participate:\n",
    "- (i) Updown (using target_updown as target)\n",
    "- (ii) Market Neutral (using target_neutral as target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "fXtsZDa_Y9KG"
   },
   "outputs": [],
   "source": [
    "# X is all the columns except the 'symbol', 'target_updown', 'target_neutral'\n",
    "X = train_dataset.iloc[:, 1:-2]\n",
    "\n",
    "# y is just the target\n",
    "y_updown = train_dataset.target_updown\n",
    "y_neutral = train_dataset.target_neutral\n",
    "\n",
    "# symbols\n",
    "symbols = train_dataset.symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "NdDHRsZpY9KG"
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hBHF03pEWKKP"
   },
   "outputs": [],
   "source": [
    "y_updown.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lS39GWEeWKKP"
   },
   "outputs": [],
   "source": [
    "y_neutral.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7QTipPuWKKP"
   },
   "source": [
    "### Split X, y into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFTC5_qKWKKP"
   },
   "outputs": [],
   "source": [
    "train = 0.9\n",
    "test = 0.1\n",
    "era = len(X.index.unique())\n",
    "train_era = int(era * train)\n",
    "test_era = era - train_era\n",
    "print('total Era: {}'.format(era))\n",
    "print('train Era: {}'.format(train_era))\n",
    "print('test Era: {}'.format(test_era))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mCoWm55YWKKP"
   },
   "outputs": [],
   "source": [
    "#split train and test set according to the train_era and test_era\n",
    "X_train = X[X.index < X.index.unique()[train_era]]\n",
    "y_updown_train = y_updown[y_updown.index < y_updown.index.unique()[train_era]]\n",
    "y_neutral_train = y_neutral[y_neutral.index < y_neutral.index.unique()[train_era]]\n",
    "symbols_train = symbols[symbols.index < symbols.index.unique()[train_era]]\n",
    "\n",
    "X_test = X[X.index >= X.index.unique()[train_era]]\n",
    "y_updown_test = y_updown[y_updown.index >= y_updown.index.unique()[train_era]]\n",
    "y_neutral_test = y_neutral[y_neutral.index >= y_neutral.index.unique()[train_era]]\n",
    "symbols_test = symbols[symbols.index >= symbols.index.unique()[train_era]]\n",
    "\n",
    "print('X_train shape: {}'.format(X_train.shape))\n",
    "print('X_test shape: {}'.format(X_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umg7-Z9hWKKQ"
   },
   "source": [
    "## Tradeable Symbol List\n",
    "The following [77 symbols](https://docs.yiedl.ai/rci-competition/submission-guide#id-1.7-symbols-used-to-measure-the-goodness-of-submissions) are used for evaluation for both *Neutral* and *Updown* competitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26-eGS7MWKKQ"
   },
   "outputs": [],
   "source": [
    "tradeable_symbol_list = ['AAVE', 'ADA', 'ALGO', 'APE', 'APT', 'ATOM', 'AVAX', 'AXS', 'BAL', 'BCH', 'BLUR', 'BNB', 'BONK', 'BTC', 'C98', 'CAKE', 'COMP', 'CRV', 'CVX', 'DAI', 'DAO', 'DOGE', 'DOT', 'DYDX', 'EOS', 'ETC', 'ETH', 'FET', 'FIL', 'FRAX', 'FTM', 'FXS', 'GRT', 'HAI', 'HERO', 'ICP', 'IMX', 'INJ', 'LDO', 'LINK', 'LTC', 'MATIC', 'MAV', 'MBOX', 'MKR', 'MOON', 'NEAR', 'OP', 'PENDLE', 'PEPE', 'PERP', 'PIT', 'POLS', 'PYTH', 'QUACK', 'RDNT', 'RNDR', 'RPL', 'RUNE', 'SFP', 'SFUND', 'SHIB', 'SOL', 'STG', 'SUI', 'SUSHI', 'TIA', 'TOKEN', 'TRX', 'UNI', 'USDT', 'XLM', 'XMR', 'XRP', 'XTZ', 'XVS', 'YFI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnYaocrDWKKQ"
   },
   "source": [
    "## For NEUTRAL competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNmKk-ugWKKQ"
   },
   "source": [
    "### We use simple Linear Regression to train a model and check the Spearman correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CvO8MAKWKKQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg_market_neutral = LinearRegression(n_jobs=-1).fit(X_train, y_neutral_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IVPETKmbWKKQ"
   },
   "outputs": [],
   "source": [
    "# function to calculate Spearman correlation by era (mean, std, max, min)\n",
    "\n",
    "def spearman_by_era(prediction, target):\n",
    "    df = pd.DataFrame(index=target.index,\n",
    "                    data = {'prediction': prediction,\n",
    "                            'target': target}\n",
    "                    )\n",
    "\n",
    "    spearman_era_list = []\n",
    "    for era in df.index.unique():\n",
    "        era_df = df[df.index == era]\n",
    "        spearman_corr = sp.stats.spearmanr(era_df.prediction, era_df.target)[0]\n",
    "        spearman_era_list.append(spearman_corr)\n",
    "\n",
    "    mean = round(np.mean(spearman_era_list), 4)\n",
    "    std = round(np.std(spearman_era_list), 4)\n",
    "    max_val = round(np.max(spearman_era_list), 4)\n",
    "    min_val = round(np.min(spearman_era_list), 4)\n",
    "    return mean, std, max_val, min_val\n",
    "\n",
    "# function to calculate portfolio return by era (mean, std, max, min)\n",
    "\n",
    "def calculate_return(symbols, prediction, actual_return):\n",
    "    df = pd.DataFrame(index=actual_return.index,\n",
    "                    data = {'symbol': symbols,\n",
    "                            'prediction': prediction,\n",
    "                            'actual_return': actual_return}\n",
    "                    )\n",
    "\n",
    "    dfs = df[df.symbol.isin(tradeable_symbol_list)]\n",
    "\n",
    "    return_era_list = []\n",
    "    for era in dfs.index.unique():\n",
    "        era_df = dfs[dfs.index == era]\n",
    "\n",
    "        # re-rank predictions to build a market neutral strategy\n",
    "        ranks = sp.stats.rankdata(era_df.prediction)\n",
    "        norm_ranks = [(r - 1) / (len(ranks) - 1) for r in ranks]\n",
    "\n",
    "        # compute allocations\n",
    "        tot = sum((abs(2 * n - 1) for n in norm_ranks))\n",
    "        allocations = [(2 * n - 1) / tot for n in norm_ranks]\n",
    "\n",
    "        # compute gain as dot product between allocation and relative deltas\n",
    "        pct_gain = np.dot(allocations, era_df.actual_return)\n",
    "\n",
    "        return_era_list.append(pct_gain)\n",
    "\n",
    "    mean = round(np.mean(return_era_list), 4)\n",
    "    std = round(np.std(return_era_list), 4)\n",
    "    max = round(np.max(return_era_list), 4)\n",
    "    min = round(np.min(return_era_list), 4)\n",
    "    return mean, std, max, min\n",
    "\n",
    "y_pred_train = reg_market_neutral.predict(X_train)\n",
    "train_spearman = spearman_by_era(y_pred_train, y_neutral_train)\n",
    "print('Train dataset Spearman correlation by era: mean = {} ; std = {} ; max = {} ; min = {}'.format(train_spearman[0],\n",
    "                                                                                             train_spearman[1],\n",
    "                                                                                             train_spearman[2],\n",
    "                                                                                             train_spearman[3]))\n",
    "\n",
    "y_pred_test = reg_market_neutral.predict(X_test)\n",
    "test_spearman = spearman_by_era(y_pred_test, y_neutral_test)\n",
    "print('Test dataset Spearman correlation by era: mean = {} ; std = {} ; max = {} ; min = {}'.format(test_spearman[0],\n",
    "                                                                                             test_spearman[1],\n",
    "                                                                                             test_spearman[2],\n",
    "                                                                                             test_spearman[3]))\n",
    "\n",
    "train_return = calculate_return(symbols_train, y_pred_train, y_updown_train)\n",
    "print('Train dataset return by era: mean = {} ; std = {} ; max = {} ; min = {}'.format(train_return[0],\n",
    "                                                                                 train_return[1],\n",
    "                                                                                 train_return[2],\n",
    "                                                                                 train_return[3]))\n",
    "\n",
    "test_return = calculate_return(symbols_test, y_pred_test, y_updown_test)\n",
    "print('Test dataset return by era: mean = {} ; std = {} ; max = {} ; min = {}'.format(test_return[0],\n",
    "                                                                                 test_return[1],\n",
    "                                                                                 test_return[2],\n",
    "                                                                                 test_return[3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ejE1lCGmWKKR"
   },
   "outputs": [],
   "source": [
    "# Use the trained Linear Regression model to make prediction on latest data\n",
    "\n",
    "X_validation = validation_dataset.iloc[:, 1:-2]\n",
    "y_validation_market_neutral = reg_market_neutral.predict(X_validation)\n",
    "\n",
    "y_validation_market_neutral[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGL0J2O9WKKR"
   },
   "source": [
    "### Let's use the prediction from linear regression to join with validation dataset symbol for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4U-kqXubWKKR"
   },
   "outputs": [],
   "source": [
    "prediction_market_neutral = pd.DataFrame()\n",
    "prediction_market_neutral['symbol'] = list(validation_dataset.symbol)\n",
    "prediction_market_neutral['prediction'] = y_validation_market_neutral\n",
    "prediction_market_neutral = prediction_market_neutral[prediction_market_neutral.symbol.isin(tradeable_symbol_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46xR-GLKWKKR"
   },
   "source": [
    "### Check is the prediction in accordance for submission format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGnPHADaWKKR"
   },
   "outputs": [],
   "source": [
    "#check if y_latest is in accordance to shape for submission and required symbols\n",
    "if set(prediction_market_neutral.symbol) == set(tradeable_symbol_list):\n",
    "    print('symbol matched!')\n",
    "else:\n",
    "    print('symbol unmatched, the symbol in prediction df must match the symbol in validation_dataset...')\n",
    "\n",
    "if prediction_market_neutral.shape[1] == 2:\n",
    "    print('column counts ok!')\n",
    "else:\n",
    "    print('It should have 2 columns, first column with symbol, second with prediction...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-eLUMgIWKKR"
   },
   "source": [
    "### Output prediction as a .csv file for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFcqPaULWKKR"
   },
   "outputs": [],
   "source": [
    "neutral_submission_file_path = neutral_submitter.save_df_to_csv(prediction_market_neutral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsBjxMiIWKKR"
   },
   "source": [
    "## For UPDOWN competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfqcB-flWKKR"
   },
   "source": [
    "### For demonstration we could also use Linear Regression to train a model and check the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0sKlgY4WKKR"
   },
   "outputs": [],
   "source": [
    "reg_updown = LinearRegression(n_jobs=-1).fit(X_train, y_updown_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHXbg-o-WKKR"
   },
   "outputs": [],
   "source": [
    "# function to calculate RMSE by era (mean, std, max, min)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rmse_by_era(prediction, target):\n",
    "    df = pd.DataFrame(index=target.index,\n",
    "                    data = {'prediction': prediction,\n",
    "                            'target': target}\n",
    "                    )\n",
    "\n",
    "    rmse_era_list = []\n",
    "    for era in df.index.unique():\n",
    "        era_df = df[df.index == era]\n",
    "        mse = mean_squared_error(era_df.target, era_df.prediction)\n",
    "        rmse = np.sqrt(mse)\n",
    "        rmse_era_list.append(rmse)\n",
    "\n",
    "    mean = round(np.mean(rmse_era_list), 4)\n",
    "    std = round(np.std(rmse_era_list), 4)\n",
    "    max_val = round(np.max(rmse_era_list), 4)\n",
    "    min_val = round(np.min(rmse_era_list), 4)\n",
    "    return mean, std, max_val, min_val\n",
    "\n",
    "\n",
    "y_pred_train = reg_updown.predict(X_train)\n",
    "train_rmse_stat = rmse_by_era(y_pred_train, y_updown_train)\n",
    "print('Train dataset RMSE by era: mean = {} ; std = {} ; max = {} ; min = {}'.format(train_rmse_stat[0],\n",
    "                                                                             train_rmse_stat[1],\n",
    "                                                                             train_rmse_stat[2],\n",
    "                                                                             train_rmse_stat[3]))\n",
    "y_pred_test = reg_updown.predict(X_test)\n",
    "test_rmse_stat = rmse_by_era(y_pred_test, y_updown_test)\n",
    "print('Test dataset RMSE by era: mean = {} ; std = {} ; max = {} ; min = {}'.format(test_rmse_stat[0],\n",
    "                                                                             test_rmse_stat[1],\n",
    "                                                                             test_rmse_stat[2],\n",
    "                                                                             test_rmse_stat[3]))\n",
    "\n",
    "train_return = calculate_return(symbols_train, y_pred_train, y_updown_train)\n",
    "print('Train dataset return by era: mean = {} ; std = {} ; max = {} ; min = {}'.format(train_return[0],\n",
    "                                                                                 train_return[1],\n",
    "                                                                                 train_return[2],\n",
    "                                                                                 train_return[3]))\n",
    "\n",
    "test_return = calculate_return(symbols_test, y_pred_test, y_updown_test)\n",
    "print('Test dataset return by era: mean = {} ; std = {} ; max = {} ; min = {}'.format(test_return[0],\n",
    "                                                                                 test_return[1],\n",
    "                                                                                 test_return[2],\n",
    "                                                                                 test_return[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C5kFPMeFWKKS"
   },
   "outputs": [],
   "source": [
    "# Use the trained Linear Regression model to make prediction on latest data\n",
    "\n",
    "X_validation = validation_dataset.iloc[:, 1:-2]\n",
    "y_validation_updown = reg_updown.predict(X_validation)\n",
    "\n",
    "y_validation_updown[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6DTEH8nWKKS"
   },
   "source": [
    "### Let's use the prediction from linear regression to join with validation dataset symbol for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQW1odcvWKKS"
   },
   "outputs": [],
   "source": [
    "prediction_updown = pd.DataFrame()\n",
    "prediction_updown['symbol'] = list(validation_dataset.symbol)\n",
    "prediction_updown['prediction'] = y_validation_updown\n",
    "prediction_updown = prediction_updown[prediction_updown.symbol.isin(tradeable_symbol_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgGhWYgwWKKS"
   },
   "source": [
    "### Check is the prediction in accordance for submission format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ojBuFY4WKKS"
   },
   "outputs": [],
   "source": [
    "#check if y_latest is in accordance to shape for submission\n",
    "if set(prediction_updown.symbol) == set(tradeable_symbol_list):\n",
    "    print('symbol matched!')\n",
    "else:\n",
    "    print('symbol unmatched, the symbol in prediction df must match the symbol in validation_dataset...')\n",
    "\n",
    "if prediction_updown.shape[1] == 2:\n",
    "    print('column counts ok!')\n",
    "else:\n",
    "    print('It should have 2 columns, first column with symbol, second with prediction...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgMWO0QWWKKS"
   },
   "source": [
    "### Output prediction as a .csv file for submission!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_hYx-WuMWKKS"
   },
   "outputs": [],
   "source": [
    "updown_submission_file_path = updown_submitter.save_df_to_csv(prediction_updown)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Submit predictions to the 2 competitions on the Polygon blockchain\n",
    "\n",
    "Staking and submitting predictions involve sending transactions to the blockchain and typically take around 1-2 minutes to complete."
   ],
   "metadata": {
    "id": "OSwTf-brAK-F"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6D6TB92Y9KS"
   },
   "source": [
    "## View POL balance for wallet\n",
    "\n",
    "The same wallet is connected to both submitters in this notebook, so we can check the balances from either one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "dBAS9POZY9KS"
   },
   "outputs": [],
   "source": [
    "print(f\"POL balance for {updown_submitter.address}: {updown_submitter.get_pol_balance()} POL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## View YIEDL balance for wallet\n"
   ],
   "metadata": {
    "id": "YhDIf0ztA4aA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"YIEDL balance for {updown_submitter.address}: {updown_submitter.get_yiedl_balance()} YIEDL\")"
   ],
   "metadata": {
    "id": "dFOaU8lTAw3b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## View YIEDL staked on UPDOWN Competition by wallet\n"
   ],
   "metadata": {
    "id": "wn4dZNL6CDeF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"YIEDL staked on UPDOWN Competition by {updown_submitter.address}: {updown_submitter.get_stake()} YIEDL\")"
   ],
   "metadata": {
    "id": "LJULctk7CDeG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## View YIEDL staked on NEUTRAL Competition by wallet\n"
   ],
   "metadata": {
    "id": "ROS0H1tWBB4i"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"YIEDL staked on NEUTRAL Competition by {neutral_submitter.address}: {neutral_submitter.get_stake()} YIEDL\")"
   ],
   "metadata": {
    "id": "NB8o2gaNBKEA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "DmNsByx8Y9KS"
   },
   "source": [
    "## Stake and submit to `UPDOWN` Competition.\n",
    "\n",
    "`stake_amount`: The final amount of YIEDL you want to be staked from your account.\n",
    "\n",
    "Example:\n",
    "\n",
    "- If your current stake is 100 YIEDL and you want to increase it to 120 YIEDL, set `stake_amount` to **120**. This will deposit 20 YIEDL from your account to the competition to be staked.\n",
    "\n",
    "- If you current stake is 100 YIEDL and you want to withdraw 70 YIEDL, set `stake_amount` to **30**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "l3LLJLfFY9KS"
   },
   "outputs": [],
   "source": [
    "stake_amount = 100.00\n",
    "transaction_success = updown_submitter.stake_and_submit(stake_amount, updown_submission_file_path)\n",
    "assert transaction_success, 'Stake and submit on UPDOWN failed.'\n",
    "print(\"Stake and submit on UPDOWN completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"YIEDL staked on UPDOWN Competition by {updown_submitter.address}: {updown_submitter.get_stake()} YIEDL\")"
   ],
   "metadata": {
    "id": "VN4R1dWEDx42"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "_VXPAvsPY9KS"
   },
   "source": [
    "## Stake and submit to `NEUTRAL` Competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "QWhiMYkfY9KT"
   },
   "outputs": [],
   "source": [
    "stake_amount = 100.00\n",
    "transaction_success = neutral_submitter.stake_and_submit(stake_amount, neutral_submission_file_path)\n",
    "assert transaction_success, 'Stake and submit on NEUTRAL failed.'\n",
    "print(\"Stake and submit on NEUTRAL completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"YIEDL staked on NEUTRAL Competition by {neutral_submitter.address}: {neutral_submitter.get_stake()} YIEDL\")"
   ],
   "metadata": {
    "id": "l00ZX35AD4qv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The methods `.set_stake(<stake_amount>)` and `.submit(<submission_file_path>)` are also available if you wish to perform these actions seperately."
   ],
   "metadata": {
    "id": "zsi_vDWKD-qS"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "tB46ciY3Y9KT"
   },
   "source": [
    "## Retrieve and double-check UPDOWN submission. (optional)\n",
    "This section retrieves your submitted files, decrypts them, and compares them to the original file.\n",
    "\n",
    "If the verification fails, please wait a few minutes and perform the verification again. If the problem persists, please re-submit your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "3PAEMsN_Y9KT"
   },
   "outputs": [],
   "source": [
    "verification_success = updown_submitter.download_and_check(updown_submission_file_path)\n",
    "assert verification_success, 'UPDOWN submission verification failed.'\n",
    "print('Files are identical. UPDOWN verification check passed.')\n",
    "updown_stake = updown_submitter.get_stake()\n",
    "print(f'UPDOWN Stake: {updown_stake:.3f} YIEDL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "wHOgZ_sSY9KT"
   },
   "source": [
    "### Retrieve and double-check NEUTRAL submission. (optional)\n",
    "This section retrieves your submitted files, decrypts them, and compares them to the original file.\n",
    "\n",
    "If the verification fails, please wait a few minutes and perform the verification again. If the problem persists, please re-submit your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Kf5Hjc9aY9KT"
   },
   "outputs": [],
   "source": [
    "verification_success = neutral_submitter.download_and_check(neutral_submission_file_path)\n",
    "assert verification_success, 'NEUTRAL submission verification failed.'\n",
    "print('Files are identical. NEUTRAL verification check passed.')\n",
    "neutral_stake = neutral_submitter.get_stake()\n",
    "print(f'NEUTRAL Stake: {neutral_stake:.3f} YIEDL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVgmEtqyY9KT"
   },
   "source": [
    "### Withdraw Submissions (an example)\n",
    "\n",
    "The following is an example of how to withdraw your stake and submission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LX_Z4ex0Y9KT"
   },
   "outputs": [],
   "source": [
    "withdraw_success = updown_submitter.withdraw()\n",
    "assert withdraw_success, \"Withdraw failed.\"\n",
    "print(\"Withdraw from UPDOWN completed.\")\n",
    "\n",
    "updown_stake = updown_submitter.get_stake()\n",
    "print(f'UPDOWN Stake: {updown_stake:.3f} YIEDL')\n",
    "\n",
    "print(f\"YIEDL balance for {updown_submitter.address} after withdrawal: {updown_submitter.get_yiedl_balance()} YIEDL\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edae17e9d04636160157afaf39070a19cd5420bcd83b30472a907092c0e31e2f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
